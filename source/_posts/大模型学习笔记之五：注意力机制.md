---
title: 大模型学习笔记之五：注意力机制
date: 2024-08-04 16:37:25
tags:
---


传统神经网络在特征提取和强化方面存在不足，注意力机制，不仅减少了层次深度，还有效提高了系统精度，同时捕获了远程依赖信息，因此深度学习及神经网络中得以迅速发展。

1. 注意力机制**直接建立输入与输出之间的依赖关系**，而不再通过循环，从而能够聚焦关键信息而忽略不相关的信息，并行化程度和运行速度显著提高。
2. 传统神经网络在输入长度增加时性能下降，而注意力机制能够有效地建模**可变长度的序列数据**，从而提高系统的性能。
3. 传统神经网络在处理**不合理的输入顺序**时计算效率低下，而注意力机制能够减少这种效率问题。


---

## 参考文献

- [注意力机制在图神经网络模型中的算法研究](https://pdf.hanspub.org/MOS20240100000_68041811.pdf)
