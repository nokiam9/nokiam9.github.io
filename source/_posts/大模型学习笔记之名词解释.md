---
title: 大模型学习笔记之名词解释
date: 2024-08-03 22:26:53
tags:
---

神经网络的三要素通常指的是：

1. 模型结构（Architecture）：这是指神经网络的拓扑结构，包括层数、每层的神经元数量、神经元之间的连接方式等。例如，一个简单的多层感知机（MLP）包含输入层、一个或多个隐藏层以及输出层。
2. 学习策略（Learning Strategy）：涉及如何选择训练神经网络的方法，包括损失函数的选择、优化算法等。损失函数定义了模型预测与实际结果之间的差异如何计算，而优化算法则用于调整网络的权重以最小化损失函数。
3. 激活函数（Activation Function）：决定了神经网络如何处理和传递信息。它们通常用于在网络的每个神经元中引入非线性，使得网络能够学习和模拟复杂的函数映射。

## 常见的名词解释

### MOE（Mixture of Experts，专家混合）模型

MOE 是一种深度学习架构，它将多个专家（experts）网络组合在一起，并通过一个门控（gating）网络来决定每个输入样本应该由哪个专家网络来处理。每个专家网络通常是一个小型的神经网络，它们专注于学习数据的不同部分或特征。

### 过拟合 & 泛化

### 梯度消失、梯度爆炸

### dropout、masked

### 超参数

学习率（learning rate，例如 10%）也是超参数，可以动态吗？

### SVM（Support Vector Machine，支持向量机）

SVM 是一种监督学习算法，主要用于分类和回归分析。它在解决小样本、非线性、高维数据的问题上表现出色，因此在机器学习领域得到了广泛的应用。

### Perceptron（感知机）

Perceptron 是最早的人工神经网络模型之一，由 Frank Rosenblatt 在 1957 年提出。它是一种简单的线性二分类模型，用于处理和分类数据。

感知机由输入层、权重、偏置项和激活函数组成。输入层接收多个输入特征，每个特征都有一个对应的权重。输入特征和权重的点积加上偏置项构成了感知机的净输入。

感知机可以看作是现代神经网络的一个特例，其中每个神经元只进行线性计算。现代神经网络通过堆叠多个感知机层（隐藏层）和引入非线性激活函数，能够解决更复杂的问题。

### Kernel Function（核函数）

核函数（Kernel Function）是机器学习中的一种数学工具，主要目的是将数据映射到一个更高维的空间，以便在这个新空间中应用线性模型来解决原始空间中的非线性问题。

常见的核函数有：线性核、多项式核、径向基函数核（Radial Basis Function Kernel，RBF，就是高斯核），Sigmod 核等。

核函数是 SVM 处理非线性问题的关键技术，它允许 SVM 在高维特征空间中进行有效的线性分割，同时避免了直接在高维空间中进行计算的高成本。通过精心选择核函数和调整其参数，SVM 能够应用于各种复杂的数据集和问题。

---

## 参考文献

- []()